{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import hyperopt as hpo\n",
    "from hyperopt.fmin import generate_trials_to_calculate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from hyperopt import hp\n",
    "space = {\n",
    "    'width': hp.uniform('width', 0, 20),\n",
    "    'height': hp.uniform('height', -100, 100),\n",
    "    'activation': hp.choice(\"activation\", [\"relu\", \"tanh\"])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HyperOptSearch():\n",
    "\n",
    "    def __init__(self,\n",
    "                 space,\n",
    "                 max_concurrent=10,\n",
    "                 reward_attr=\"episode_reward_mean\",\n",
    "                 points_to_evaluate=None,\n",
    "                 **kwargs):\n",
    "        assert hpo is not None, \"HyperOpt must be installed!\"\n",
    "        assert type(max_concurrent) is int and max_concurrent > 0\n",
    "        self._max_concurrent = max_concurrent\n",
    "        self._reward_attr = reward_attr\n",
    "        self.algo = hpo.tpe.suggest\n",
    "        self.domain = hpo.Domain(lambda spc: spc, space)\n",
    "        if points_to_evaluate is None:\n",
    "            self._hpopt_trials = hpo.Trials()\n",
    "            self._points_to_evaluate = 0\n",
    "        else:\n",
    "            assert type(points_to_evaluate) == list\n",
    "            self._hpopt_trials = generate_trials_to_calculate(\n",
    "                points_to_evaluate)\n",
    "            self._hpopt_trials.refresh()\n",
    "            self._points_to_evaluate = len(points_to_evaluate)\n",
    "        self._live_trial_mapping = {}\n",
    "        self.rstate = np.random.RandomState()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = HyperOptSearch(space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _num_live_trials():\n",
    "    return len(opt._live_trial_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## suggest(self, trial_id):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_id = ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 10\n"
     ]
    }
   ],
   "source": [
    "print(_num_live_trials(), opt._max_concurrent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "print(opt._points_to_evaluate)\n",
    "if opt._points_to_evaluate > 0:\n",
    "    new_trial = opt._hpopt_trials.trials[opt._points_to_evaluate - 1]\n",
    "    opt._points_to_evaluate -= 1\n",
    "    print(opt._points_to_evaluate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "[0]\n",
      "\n",
      "opt._hpopt_trials: \n",
      "{'_ids': {0}, '_dynamic_trials': [], '_exp_key': None, 'attachments': {}, '_trials': []}\n",
      "\n",
      "new_trials: \n",
      "[{'state': 0, 'tid': 0, 'spec': None, 'result': {'status': 'new'}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'activation': [0], 'height': [0], 'width': [0]}, 'vals': {'activation': [1], 'height': [-73.7756456093657], 'width': [18.149351186699228]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': None, 'refresh_time': None}]\n",
      "\n",
      "{'_ids': {0}, '_dynamic_trials': [{'state': 0, 'tid': 0, 'spec': None, 'result': {'status': 'new'}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'activation': [0], 'height': [0], 'width': [0]}, 'vals': {'activation': [1], 'height': [-73.7756456093657], 'width': [18.149351186699228]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': None, 'refresh_time': None}], '_exp_key': None, 'attachments': {}, '_trials': [{'state': 0, 'tid': 0, 'spec': None, 'result': {'status': 'new'}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'activation': [0], 'height': [0], 'width': [0]}, 'vals': {'activation': [1], 'height': [-73.7756456093657], 'width': [18.149351186699228]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': None, 'refresh_time': None}]}\n",
      "\n",
      "{'state': 0, 'tid': 0, 'spec': None, 'result': {'status': 'new'}, 'misc': {'tid': 0, 'cmd': ('domain_attachment', 'FMinIter_Domain'), 'workdir': None, 'idxs': {'activation': [0], 'height': [0], 'width': [0]}, 'vals': {'activation': [1], 'height': [-73.7756456093657], 'width': [18.149351186699228]}}, 'exp_key': None, 'owner': None, 'version': 0, 'book_time': None, 'refresh_time': None}\n"
     ]
    }
   ],
   "source": [
    "print(opt._points_to_evaluate)\n",
    "\n",
    "if opt._points_to_evaluate <= 0:\n",
    "    new_ids = opt._hpopt_trials.new_trial_ids(1)\n",
    "    print(new_ids); print()\n",
    "    \n",
    "    opt._hpopt_trials.refresh()\n",
    "    print('opt._hpopt_trials: '); print(opt._hpopt_trials.__dict__); print()\n",
    "\n",
    "    # Get new suggestion from Hyperopt\n",
    "    new_trials = opt.algo(new_ids, opt.domain, opt._hpopt_trials, opt.rstate.randint(2**31 - 1))\n",
    "    print('new_trials: '); print(new_trials); print()\n",
    "    \n",
    "    opt._hpopt_trials.insert_trial_docs(new_trials)\n",
    "    opt._hpopt_trials.refresh()\n",
    "    print('opt._hpopt_trials: '); print(opt._hpopt_trials.__dict__); print()\n",
    "    \n",
    "    new_trial = new_trials[0]\n",
    "    print('new_trial: '); print(new_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trial_id' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-81-177b614ae4cb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_live_trial_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnew_trial\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"tid\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_trial\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_live_trial_mapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'trial_id' is not defined"
     ]
    }
   ],
   "source": [
    "opt._live_trial_mapping[trial_id] = (new_trial[\"tid\"], new_trial)\n",
    "print(opt._live_trial_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Taken from HyperOpt.base.evaluate\n",
    "config = hpo.base.spec_from_misc(new_trial[\"misc\"])\n",
    "ctrl = hpo.base.Ctrl(self._hpopt_trials, current_trial=new_trial)\n",
    "memo = opt.domain.memo_from_config(config)\n",
    "hpo.utils.use_obj_for_literal_in_memo(opt.domain.expr, ctrl,\n",
    "                                      hpo.base.Ctrl, memo)\n",
    "\n",
    "suggested_config = hpo.pyll.rec_eval(\n",
    "            opt.domain.expr,\n",
    "            memo=memo,\n",
    "            print_node_on_error=opt.domain.rec_eval_print_node_on_error)\n",
    "\n",
    "print(suggested_config)\n",
    "# copy.deepcopy(suggested_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def on_trial_result(self, trial_id, result):\n",
    "    print(ho_trial); print()\n",
    "    ho_trial = self._get_hyperopt_trial(trial_id)\n",
    "    if ho_trial is None:\n",
    "        return\n",
    "    now = hpo.utils.coarse_utcnow()\n",
    "    ho_trial['book_time'] = now\n",
    "    ho_trial['refresh_time'] = now\n",
    "    print(ho_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "print(self._live_trial_mapping)\n",
    "self._live_trial_mapping[trial_id] = (new_trial[\"tid\"], new_trial)\n",
    "print(self._live_trial_mapping)\n",
    "\n",
    "# Taken from HyperOpt.base.evaluate\n",
    "config = hpo.base.spec_from_misc(new_trial[\"misc\"])\n",
    "print(config)\n",
    "ctrl = hpo.base.Ctrl(self._hpopt_trials, current_trial=new_trial)\n",
    "print(ctrl)\n",
    "memo = self.domain.memo_from_config(config)\n",
    "hpo.utils.use_obj_for_literal_in_memo(self.domain.expr, ctrl,\n",
    "                                      hpo.base.Ctrl, memo)\n",
    "\n",
    "suggested_config = hpo.pyll.rec_eval(\n",
    "    self.domain.expr,\n",
    "    memo=memo,\n",
    "    print_node_on_error=self.domain.rec_eval_print_node_on_error)\n",
    "return copy.deepcopy(suggested_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
